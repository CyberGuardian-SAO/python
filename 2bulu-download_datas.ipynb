{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "download datas",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "16hfm29WhiZfk0ot98ygCWRP7GOU3dsFS",
      "authorship_tag": "ABX9TyMl7pNuCtWNjxhjVW4J0yVy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CyberGuardian-SAO/python-2bulu/blob/master/2bulu-download_datas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "j--CNrIRi-rA",
        "outputId": "7ee21bfa-0ff0-4582-c1b0-0c62a028afc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#生成页面\n",
        "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36',\n",
        "           'Cookie':'UM_distinctid=17047f9723c1-00ad6085cfe524-313f69-15c000-17047f9724470; JSESSIONID=797A1484051DF3D929A87FFE82AD7989-n2; CNZZDATA1000341086=438850946-1581752503-null%7C1584245957'}\n",
        "def download_all_htmls():\n",
        "    \"\"\"\n",
        "    下载所有列表页面的HTML，用于后续的分析\n",
        "    \"\"\"\n",
        "    htmls = []\n",
        "    for idx in range(3):\n",
        "      #韭菜岭http://www.2bulu.com/track/list-%E9%9F%AD%E8%8F%9C%E5%B2%AD-----1.htm?sortType=2\n",
        "      #舜皇山http://www.2bulu.com/track/list-%E8%88%9C%E7%9A%87%E5%B1%B1-----1.htm?sortType=2\n",
        "        url = f\"http://www.2bulu.com/track/list-%E9%9F%AD%E8%8F%9C%E5%B2%AD-----{idx+1}.htm?sortType=2\"\n",
        "        print(url)\n",
        "        r = requests.get(url)\n",
        "        if r.status_code != 200:\n",
        "            raise Exception(\"error\")\n",
        "        htmls.append(r.text)\n",
        "    return htmls\n",
        "htmls = download_all_htmls()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.2bulu.com/track/list-%E9%9F%AD%E8%8F%9C%E5%B2%AD-----1.htm?sortType=2\n",
            "http://www.2bulu.com/track/list-%E9%9F%AD%E8%8F%9C%E5%B2%AD-----2.htm?sortType=2\n",
            "http://www.2bulu.com/track/list-%E9%9F%AD%E8%8F%9C%E5%B2%AD-----3.htm?sortType=2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "3d703a48-f705-4ced-ae5d-8e555848e5db",
        "id": "-WY62UZp7xez",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        "from selenium import webdriver\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "driver = webdriver.Chrome('chromedriver', chrome_options=chrome_options)\n",
        "def get_page_sourse():\n",
        "  htmls = []\n",
        "  for idx in range(3):\n",
        "    url = f\"http://www.2bulu.com/track/list-%E9%9F%AD%E8%8F%9C%E5%B2%AD-----{idx+1}.htm?sortType=2\"\n",
        "    driver.get(url)   # 要测试的页面\n",
        "    htmls=driver.page_source\n",
        "    r = requests.get(url)\n",
        "  return htmls\n",
        "htmls=get_page_sourse()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: use options instead of chrome_options\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVwtFjOllAsL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -*- coding:utf-8 -*-\n",
        "# python 3.7\n",
        "#引入系统类库\n",
        "import sys\n",
        "# 使用文档解析类库\n",
        "from bs4 import BeautifulSoup\n",
        "# 使用网络请求类库\n",
        "import urllib.request\n",
        "# 输入网址\n",
        "html_doc = \"https://www.baidu.com\"\n",
        "if len(sys.argv)>1:\n",
        "   website=sys.argv[1]\n",
        "   if(website is not None):\n",
        "        html_doc= sys.argv[1]\n",
        "# 获取请求\n",
        "req = urllib.request.Request(html_doc)\n",
        "# 打开页面\n",
        "webpage = urllib.request.urlopen(req)\n",
        "# 读取页面内容\n",
        "html = webpage.read()\n",
        "# 解析成文档对象\n",
        "soup = BeautifulSoup(html, 'html.parser')   #文档对象\n",
        "# 非法URL 1\n",
        "invalidLink1='#'\n",
        "# 非法URL 2\n",
        "invalidLink2='javascript:void(0)'\n",
        "# 集合\n",
        "result=set()\n",
        "# 计数器\n",
        "mycount=0\n",
        "#查找文档中所有a标签\n",
        "for k in soup.find_all('a'):\n",
        "    #print(k)\n",
        "    #查找href标签\n",
        "    link=k.get('href')\n",
        "    # 过滤没找到的\n",
        "    if(link is not None):\n",
        "          #过滤非法链接\n",
        "          if link==invalidLink1:\n",
        "            pass\n",
        "          elif link==invalidLink2:\n",
        "            pass\n",
        "          elif link.find(\"javascript:\")!=-1:\n",
        "            pass\n",
        "          else:\n",
        "            mycount=mycount+1\n",
        "            #print(mycount,link)\n",
        "            result.add(link)\n",
        "#print(\"打印超链接个数:\",mycount)\n",
        "#print(\"打印超链接列表\",result)\n",
        "f = open(r'result.txt','w',encoding='utf-8')  #文件路径、操作模式、编码  # r''\n",
        "for a in result:\n",
        "    f.write(a+\"\\n\")\n",
        "f.close()\n",
        "print(\"\\r\\n扫描结果已写入到result.txt文件中\\r\\n\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RomMtwdd7d7J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "import time\n",
        "import xlwt\n",
        "import urllib.request\n",
        "from urllib.request import URLError\n",
        " \n",
        "# 调用chrome浏览器并后台运行\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "driver = webdriver.Chrome('chromedriver', chrome_options=chrome_options)\n",
        "\n",
        "driver.get(\"http://www.2bulu.com/track/list-%E9%9F%AD%E8%8F%9C%E5%B2%AD-----5.htm?sortType=2\")   # 要测试的页面\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#打开网页\n",
        "\n",
        "#time.sleep(5)\n",
        " \n",
        "#获取网页信息\n",
        "html=driver.page_source\n",
        "soup=BeautifulSoup(html,'lxml')\n",
        " \n",
        "#用soup来获得所有'tr'标签\n",
        "list=soup.find_all(name='div',attrs = {'class':'guiji_discription'})\n",
        "result=[]\n",
        " \n",
        "#将所有符合规则的'tr'标签里面的内容提取出来\n",
        "for each in list:\n",
        "    key = each.find('span',{'class':'s7'})\n",
        "    point = each.find('div',{'class':'right_pic'})\n",
        "    if point !=None:\n",
        "        point = point.find('span')\n",
        "    if rank!=None and key!=None and point!=None :\n",
        "        result.append([key.string,point.string])\n",
        " \n",
        "#新建xls对象\n",
        "workbook = xlwt.Workbook(encoding = 'utf-8')\n",
        "worksheet = workbook.add_sheet('Baidu Rank Data')\n",
        "worksheet.write(0,1, label = 'key')\n",
        "worksheet.write(0,2, label = 'point')\n",
        " \n",
        "#设置列宽\n",
        "col = worksheet.col(1)\n",
        "col.width=5000\n",
        " \n",
        "#写入数据\n",
        "i=1\n",
        "for each in result:\n",
        "    rank=str(each[0])\n",
        "    key=str(each[1])\n",
        "    point=str(each[2])\n",
        "    worksheet.write(i,0,rank)\n",
        "    worksheet.write(i,1,key)\n",
        "    worksheet.write(i,2,point)\n",
        "    i+=1\n",
        " \n",
        "#保存\n",
        "workbook.save(r'C:\\Users\\me\\Desktop\\Data.xls')\n",
        " \n",
        "print(result)\n",
        "#print(len(result))\n",
        "#print(len(list))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w3cPujOq7QiC",
        "colab": {}
      },
      "source": [
        "#抓取第一级页面\n",
        "def start_requests(url):\n",
        "    print(url) # 用这条命令知道当前在抓取哪个链接，如果发生错误便于调试\n",
        "    r = requests.get(url)\n",
        "    return r.content\n",
        "\n",
        "def get_page_sourse():\n",
        "  \n",
        "  driver = webdriver.Chrome('chromedriver', chrome_options=chrome_options)\n",
        "  driver.get(url)\n",
        "  page_sourse=driver.page_source\n",
        "  driver.close()\n",
        "  return page_sourse\n",
        "\n",
        "def parse_music(text):\n",
        "  page_sourse = get_page_sourse()\n",
        "  soup = BeautifulSoup(page_sourse,\"lxml\")\n",
        "\n",
        " \n",
        "    \n",
        "   # if point !=None:\n",
        "  #jake=soup.find_all('a',target='_blank')\n",
        "  #jake=soup.find_all({'div','a','img'})\n",
        "  jakes=soup.find_all('img',onerror=\"javascript:this.src='/images/defaultTrack.png';\")\n",
        "  html_list=[]\n",
        "  #idx=0\n",
        "  for jake in jakes:#打印含有img的父标签集合\n",
        "    if jake.parent !=None:\n",
        "        html_list.append(jake.parent)\n",
        "        #idx=idx+1\n",
        "        #print(idx)检测是否逐一筛选出img页面\n",
        "  lst2 = list(set(html_list))#去重\n",
        "  #print(lst2)检测是否去重成功\n",
        "\n",
        " \n",
        "  #all_music = lst2.find_all('a', {'href': re.compile('/track/.*2$')})\n",
        "\n",
        "  pages = []\n",
        "  for link in lst2:\n",
        "    current_url = \"http://www.2bulu.com/\"\n",
        "    #if link.find('img') !=0:\n",
        "    relative_url=link['href']\n",
        "    print(relative_url)\n",
        "    complete_url = urljoin(current_url, relative_url)\n",
        "    pages.append(complete_url)\n",
        "  return pages\n",
        "\n",
        "def parse_page(text):\n",
        "    soup = BeautifulSoup(text, 'lxml')\n",
        "    mydict = {}\n",
        "    mydict['title'] = soup.find('span', id = 'track_name').text\n",
        "    mydict['duration'] = soup.find('p', class_= 'big').text\n",
        "    mydict['time'] = soup.find('span', class_= 'green_point').text\n",
        "    return mydict\n",
        "\n",
        "def write_json(result):\n",
        "    s = json.dumps(result, indent = 4, ensure_ascii=False)\n",
        "    with open('movies.json', 'w', encoding = 'utf-8') as f:\n",
        "        f.write(s)\n",
        "\n",
        "for idx in range(3):\n",
        "  result_list = []\n",
        "  url = f\"http://www.2bulu.com/track/list-%E9%9F%AD%E8%8F%9C%E5%B2%AD-----{idx+1}.htm?sortType=2\"\n",
        "  print(\"当前正在打印的页码是：\",idx+1)\n",
        "  text = start_requests(url)\n",
        "  pageurls = parse_music(text)\n",
        "  for pageurl in pageurls:\n",
        "    page = start_requests(pageurl)\n",
        "    mydict = parse_page(page)\n",
        "    result_list.append(mydict)\n",
        "  write_json(result_list) # 所有电影都存进去之后一起输出到文件"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TAf53bME3143",
        "colab_type": "code",
        "outputId": "f28f61e1-9262-4c9c-c00a-46a72085b2d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#生成图片和标签数据\n",
        "def parse_music():\n",
        "  url=\"http://www.2bulu.com/track/t-2hzcA6K5wYvp%252FR2KBg5Tzw%253D%253D.htm?tabType=2\"\n",
        "  driver = webdriver.Chrome('chromedriver', options=options)\n",
        "  driver.get(url)\n",
        "  page_sourse=driver.page_source\n",
        "  #print(page_sourse)\n",
        "  soup = BeautifulSoup(page_sourse, 'lxml')\n",
        "  #print(soup)\n",
        "  lis = soup.find(\"ul\", id =\"track_marker_div\")\n",
        "  print(lis)\n",
        "  datas=[]\n",
        "  for li in lis: \n",
        "    times=li.find('p',class_='date').text\n",
        "    if re.findall(r'\\d{1,4}-\\d{1,2}-\\d{1,2} \\d{1,2}:\\d{1,2}', times):\n",
        "      result_year = time.strftime(\"%Y\", time.strptime(times, \"%Y-%m-%d %H:%M:%S\"))\n",
        "      result_month = time.strftime(\"%m\", time.strptime(times, \"%Y-%m-%d %H:%M:%S\"))   \n",
        "      result_day = time.strftime(\"%d\", time.strptime(times, \"%Y-%m-%d %H:%M:%S\")) #strptime作用是将第1个参数的格式与第2个参数匹配\n",
        "      result_hour = time.strftime(\"%H\", time.strptime(times, \"%Y-%m-%d %H:%M:%S\"))#strftime作用将第2个参数输出成第1个参数的形式\n",
        "    #names=li.find('p',class_='text').text\n",
        "    name=li.find('p',{\"class\": re.compile('[^\\d,\\.]+')}).string\n",
        "    names=re.findall('[^\\s,\\d,\\.:,\\-]+',name)#实现匹配除空格、数字、标点(.)的字符\n",
        "    link=li.find('img',class_='lazy_img')\n",
        "    if (link is not None): \n",
        "      links = link[\"data-original\"]\n",
        "      id=li.find('div',class_='point').get('id')\n",
        "      id=int(id)#id是属性值，所以要强转为int型\n",
        "      datas.clear()#清空datas中的数据\n",
        "      datas.append({\"n\":names,\"年\":result_year,\"月\":result_month,\"日\":result_day,\"时\":result_hour,\"id\":id}) \n",
        "    #下载照片\n",
        "      response = requests.get(links) #获取请求\n",
        "    #name = '233'  #图片名称\n",
        "      fb = open('/content/图片/%s.jpg'%str(id),'wb')  #wb代表以二进制方式写入\n",
        "      fb.write(response.content)  #写入\n",
        "      fb.close()  #关闭\n",
        "    #下载标签数据\n",
        "      with open(\"/content/json/%s.json\"%str(id), \"w\") as fout:\n",
        "        for data in datas:\n",
        "          fout.write(json.dumps(data, ensure_ascii=False)+\"\\n\")\n",
        "    else:\n",
        "      pass\n",
        "    #以src命名图片和json文件\n",
        "  return datas  \n",
        "\n",
        "parse_music()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<ul class=\"biaozhu_list\" id=\"track_marker_div\"><li><div class=\"point\" id=\"203666343\" marker_id=\"203666343\"><div class=\"info\"><div class=\"info_show on\"><img alt=\"\" src=\"/images/track/biaozhu.png\"/><a href=\"#\">0.04km</a></div><div class=\"biaozhu_pic\"><a class=\"group_markImg\" href=\"https://down-files.2bulu.com/f/d1?downParams=E6rpf59vd5EKBLYt1Quxlw%3D%3D%0A\" markerindex=\"1\" rel=\"group_markImg\"><img class=\"lazy_img\" data-original=\"https://down-files.2bulu.com/f/d1?downParams=E6rpf59vd5HWiY55Llxrug%3D%3D%0A\" src=\"https://down-files.2bulu.com/f/d1?downParams=E6rpf59vd5HWiY55Llxrug%3D%3D%0A\" style=\"display: inline;\"/><span class=\"point_img_ok\"></span></a><p class=\"date\">2019-12-06 08:52:38</p></div></div></div></li><li><div class=\"point\" id=\"203666344\" marker_id=\"203666344\"><div class=\"info\"><div class=\"info_show on\"><img alt=\"\" src=\"/images/track/biaozhu.png\"/><a href=\"#\">0.19km</a></div><div class=\"biaozhu_pic\"><a class=\"group_markImg\" href=\"https://down-files.2bulu.com/f/d1?downParams=E6rpf59vd5EwlEME86zMoQ%3D%3D%0A\" markerindex=\"2\" rel=\"group_markImg\"><img class=\"lazy_img\" data-original=\"https://down-files.2bulu.com/f/d1?downParams=E6rpf59vd5FIGvigxHrhLA%3D%3D%0A\" src=\"https://down-files.2bulu.com/f/d1?downParams=E6rpf59vd5FIGvigxHrhLA%3D%3D%0A\" style=\"display: inline;\"/><span class=\"point_img_ok\"></span></a><p class=\"date\">2019-12-06 08:55:02</p></div></div></div></li><li><div class=\"point\" id=\"203666345\" marker_id=\"203666345\"><div class=\"info\"><div class=\"info_show on\"><img alt=\"\" src=\"/images/track/biaozhu.png\"/><a href=\"#\">0.45km</a></div><div class=\"biaozhu_pic\"><a class=\"group_markImg\" href=\"https://down-files.2bulu.com/f/d1?downParams=E6rpf59vd5Eef9MgRK08oQ%3D%3D%0A\" markerindex=\"3\" rel=\"group_markImg\"><img class=\"lazy_img\" data-original=\"https://down-files.2bulu.com/f/d1?downParams=E6rpf59vd5EMauGYU0u%2Biw%3D%3D%0A\" src=\"https://down-files.2bulu.com/f/d1?downParams=E6rpf59vd5EMauGYU0u%2Biw%3D%3D%0A\" style=\"display: inline;\"/><span class=\"point_img_ok\"></span></a><p class=\"date\">2019-12-06 09:02:48</p></div></div></div></li></ul>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 203666345, 'n': [], '年': '2019', '日': '06', '时': '09', '月': '12'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP4wdBgNwHbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#json转xml\n",
        "import xmltodict\n",
        "import json\n",
        "import os\n",
        "\n",
        "# json to xml\n",
        "def jsonToXml(json_str):\n",
        "    try:\n",
        "        xml_str=\"\"\n",
        "        xml_str = xmltodict.unparse(json_str, encoding='utf-8')\n",
        "    except:\n",
        "        xml_str = xmltodict.unparse({'request': json_str}, encoding='utf-8')\n",
        "    finally:\n",
        "        return xml_str\n",
        "\n",
        "def json_to_xml(json_path,xml_path):\n",
        "    if(os.path.exists(xml_path)==False):\n",
        "        os.makedirs(xml_path)\n",
        "    dir = os.listdir(json_path)\n",
        "    for file in dir:\n",
        "        file_list=file.split(\".json\")#以.json为单位进行切割\n",
        "        with open(os.path.join(json_path,file), 'r') as load_f:\n",
        "            load_dict = json.load(load_f)\n",
        "        json_result = jsonToXml(load_dict)\n",
        "        f = open(os.path.join(xml_path,file_list[0]+\".xml\"), 'w', encoding=\"UTF-8\")\n",
        "        f.write(json_result)\n",
        "        f.close()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    json_path=r\"/content/drive/My Drive/json\"  #该目录为存放json文件的路径  ps:目录中只能存放json文件\n",
        "    xml_path=r\"/content/drive/My Drive/xml\"   #该目录为放xml文件的路径\n",
        "    json_to_xml(json_path,xml_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9lLBsr1rmDH",
        "colab_type": "code",
        "outputId": "60914ad2-98b1-4a8c-d12a-94fd2d4c1434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import hashlib\n",
        "\n",
        "def get_token(filename):\n",
        "    #pic = new.strip() # or new.split()[index]\n",
        "    #hs = hashlib.md5(new.encode()).hexdigest()\n",
        "    #print(pic)\n",
        "    #m1 = hashlib.md5()\n",
        "    #m1.update(pic)\n",
        "    #token = m1.hexdigest()\n",
        "    #print(token)\n",
        "  with open(filename, mode='rb') as f:\n",
        "    d = hashlib.md5()\n",
        "    while True:\n",
        "      buf = f.read(4096) # 128 is smaller than the typical filesystem block\n",
        "      if not buf:\n",
        "        break\n",
        "      d.update(buf) \n",
        "    return d.hexdigest()\n",
        "    \n",
        "\n",
        "\n",
        "def find_the_same_pic(cwd, xml):\n",
        "    for path, d, filelist in os.walk(cwd):\n",
        "        filelist = sorted(filelist)\n",
        "        #filelist = filelist[600:]\n",
        "        for imgname in filelist:\n",
        "            #print(imgname)\n",
        "            if imgname.endswith('jpg'):\n",
        "                oldname1 = os.path.join(path, imgname)\n",
        "                print('the old pic : ', oldname1)\n",
        "                filelist.remove(imgname)\n",
        "                #img1 = cv2.imread(oldname1)\n",
        "                #print(img1)\n",
        "                #img1 = cv2.resize(img1, (540, 960))\n",
        "                img1md5 = get_token(oldname1)\n",
        "                for imgname1 in filelist:\n",
        "                    if imgname1.endswith('jpg'):\n",
        "                        oldname2 = os.path.join(path, imgname1)\n",
        "                        # print(oldname2)\n",
        "                        #img2 = cv2.imread(oldname2)\n",
        "                        #print(oldname2)\n",
        "                        #img2 = cv2.resize(img2, (540, 960))\n",
        "                        img2md5 = get_token(oldname2)\n",
        "                        # img = img2 - img1\n",
        "                        # a = max(sum(sum(img)))\n",
        "                        result = (img1md5 == img2md5)\n",
        "                        #result = not np.any(difference)\n",
        "\n",
        "                        if result is True :\n",
        "                            print('the_same : ', oldname1, oldname2)\n",
        "                            rm_same_pic_and_xml(cwd, imgname1, xml)\n",
        "                            filelist.remove(imgname1)\n",
        "\n",
        "                        else:\n",
        "                            pass\n",
        "def rm_same_pic_and_xml(cwd, imgname, xml):\n",
        "    xmlname = imgname.split('.')[0] + '.xml'\n",
        "\n",
        "    pic_file = os.path.join(cwd, imgname)\n",
        "    xml_file = os.path.join(xml, xmlname)\n",
        "    os.remove(pic_file)\n",
        "    os.remove(xml_file)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    cwd = r'/content/drive/My Drive/图片'\n",
        "\n",
        "    xml = r'/content/drive/My Drive/xml'\n",
        "\n",
        "\n",
        "    find_the_same_pic(cwd, xml)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the old pic :  /content/drive/My Drive/图片/100493524.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-30dcaf403fda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mfind_the_same_pic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-30dcaf403fda>\u001b[0m in \u001b[0;36mfind_the_same_pic\u001b[0;34m(cwd, xml)\u001b[0m\n\u001b[1;32m     44\u001b[0m                         \u001b[0;31m#print(oldname2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                         \u001b[0;31m#img2 = cv2.resize(img2, (540, 960))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                         \u001b[0mimg2md5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moldname2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                         \u001b[0;31m# img = img2 - img1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                         \u001b[0;31m# a = max(sum(sum(img)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-30dcaf403fda>\u001b[0m in \u001b[0;36mget_token\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmd5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m       \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 128 is smaller than the typical filesystem block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWPt2H98261Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#python抓取两步路数据\n",
        "#第一步安装必要库和接口\n",
        "#修正时间，因为Google colab服务器在美国所以输出的时间会相差8小时\n",
        "!date -R\n",
        "!apt-get install ntpdate\n",
        "!ntpdate ntp.sjtu.edu.cn\n",
        "!date -R\n",
        "import os\n",
        "os.environ['TZ'] = \"Asia/Shanghai\"\n",
        "# install chromium, its driver, and selenium\n",
        "!pip install selenium\n",
        "!pip install requests-html\n",
        "!pip install beautifulsoup4\n",
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install xmltodict\n",
        "#导入必要接口\n",
        "import urllib.request\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "import xlwt\n",
        "import bs4\n",
        "import re\n",
        "from datetime import datetime   \n",
        "from selenium import webdriver\n",
        "from urllib.parse import urljoin\n",
        "from bs4 import BeautifulSoup\n",
        "#（1）加上请求头，伪装成浏览器访问下面使request加头文件的方法,如果用chromedrier则不能这样用，而要用在option.add_argument里面\n",
        "headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36',\n",
        "          'Cookie':'UM_distinctid=17047f9723c1-00ad6085cfe524-313f69-15c000-17047f9724470; JSESSIONID=797A1484051DF3D929A87FFE82AD7989-n2; CNZZDATA1000341086=438850946-1581752503-null%7C1584245957'}\n",
        "# set options to be headless, ..\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "# open it, go to a website, and get results\n",
        "#（测试是否可以得到源码）\n",
        "wd = webdriver.Chrome('chromedriver',options=options)\n",
        "wd.get(\"http://www.2bulu.com/track/list-%E9%9F%AD%E8%8F%9C%E5%B2%AD-----1.htm?sortType=2\")#输入测试网址\n",
        "#print(wd.page_source) 测试的时候就可以打开\n",
        "#上一部分和下一部分最好分成两部分执行，这样第一部分就不需要重新执行了"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnnN3mP3wjjT",
        "colab_type": "code",
        "outputId": "05779da8-6a0f-4f1a-c665-7e3f65461a4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!rm /content/图片/*\n",
        "!rm /content/json/*\n",
        "!rm /content/xml/*"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rm: cannot remove '/content/xml/*': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHw7oNt2oSKA",
        "colab_type": "code",
        "outputId": "cc0cb578-20f4-4674-ffd5-dc47f8029cf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "#第二部开始操作\n",
        "#（1）用这条命令知道当前在抓取哪个链接，如果发生错误便于调试\n",
        "def start_requests(url):      #这里的url只是传参，比如你使用这个函数的时候start_requests(gx)，它会把原来url的地方替换成gx\n",
        "    print(url)          #用这个接口打印当前在抓取哪个链接，如果发生错误便于调试\n",
        "    r = requests.get(url)   #这个接口的意思是实现访问url指代的网址\n",
        "    return r.content      #这个函数的作用是返回r的内容即requests.get得到的\n",
        "\n",
        "#（2）使用chromedriver模拟打开网页获取目标网址的源代码\n",
        "def get_page_sourse(url):\n",
        "  options = webdriver.ChromeOptions()       #定义options\n",
        "  options.add_argument('--headless')         #浏览器不提供可视化页面.linux下如果系统不支持可视化不加\n",
        "  options.add_argument('--no-sandbox')        #不启动沙盒，Bypass OS security model\n",
        "  options.add_argument('--disable-dev-shm-usage')   #overcome limited resource problems\n",
        "  options.add_argument('--disable-gpu') #谷歌文档提到需要加上这个属性来规避bug\n",
        "  options.add_argument('--hide-scrollbars') #隐藏滚动条, 应对一些特殊页面\n",
        "  #options.add_argument('blink-settings=imagesEnabled=false') #不加载图片, 提升速度，不爬图片的时候可以打开\n",
        "  #options.add_argument('--proxy-server=http://222.95.240.228:3000') #设置代理\n",
        "  options.add_argument('User-Agent:\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36\"')#chromedriver添加头的做法\n",
        "  driver = webdriver.Chrome('chromedriver', options=options) #后面3步是为了得到page_sourese即页面的源码，如果正常request取不到的话，一般用于动态加载的\n",
        "  \n",
        "  driver.get(url)\n",
        "  page_sourse=driver.page_source\n",
        "  driver.close()                  #用完driver记得关闭，节省内存空间\n",
        "  return page_sourse\n",
        "\n",
        "#（3）解析一级源代码，找到二级地址并实现拼接\n",
        "def parse_music(text):\n",
        "  page_sourse = get_page_sourse(url)       #调用上一个函数即get_page_sourse(url)来得到一级界面源码\n",
        "  soup = BeautifulSoup(page_sourse,\"lxml\")    #通过beautifulsoup中lxml解码器解析源码\n",
        "  #jake=soup.find_all('a',target='_blank'，src='images') #找a标签中，同时有target与src属性的\n",
        "  jakes=soup.find_all('img',onerror=\"javascript:this.src='/images/defaultTrack.png';\") #通过find_all找到soup中所有img标签且这个标签中含有onerror属性\n",
        "  html_list=[]                   #设置一个数组或者说集合来装符合要求的二级连接\n",
        "  #idx=0\n",
        "  for jake in jakes:              #打印含有img的父标签集合\n",
        "    if jake.parent !=None:          #加判断，把所有img中有父节点的匹配出来\n",
        "        html_list.append(jake.parent)    #通过加.append把收集好的数据存到html_list这个集合中\n",
        "        #idx=idx+1\n",
        "        #print(idx)检测是否逐一筛选出img页面\n",
        "  lst2 = list(set(html_list))          #去重，如果html_list中有重复的连接，这一步就可以去掉\n",
        "  #print(lst2)检测是否去重成功\n",
        "  #all_music = lst2.find_all('a', {'href': re.compile('/track/.*2$')}) #找list2中符合条件的href正则法\n",
        "  \n",
        "  pages = []                  #设置pages集合来装完整的一级目录集合，因为上一循环搜集到的是相对地址需要通过这个循环实现拼接\n",
        "  for link in lst2:\n",
        "    current_url = \"http://www.2bulu.com/\"  #如果是相对地址就拼接，前面需要拼接的部分填在这\n",
        "    #if link.find('img') !=0:\n",
        "    relative_url=link['href']\n",
        "    #print(relative_url)\n",
        "    complete_url = urljoin(current_url, relative_url)\n",
        "    pages.append(complete_url)\n",
        "  return pages\n",
        "#（4）解析二级目录源代码，并提取关键词和标签\n",
        "def parse_page(text):\n",
        "  #url=\"http://www.2bulu.com/track/t-ockmzMSsUKzp%252FR2KBg5Tzw%253D%253D.htm?tabType=2\"\n",
        " \n",
        "\n",
        "  \n",
        "  #print(page_sourse)\n",
        "  soup = BeautifulSoup(text, 'lxml')\n",
        "  #print(soup)查看二级页面是否也是动态加载，如果是则需要改用chrome\n",
        "  lis = soup.find(\"ul\", id =\"track_marker_div\",class_=\"biaozhu_list\")\n",
        "  #print(lis)\n",
        "  datas=[]\n",
        "  for li in lis: \n",
        "    time.sleep(1)\n",
        "    #print(li)\n",
        "    times=li.find('p',class_='date').text\n",
        "    if re.findall(r'\\d{1,4}-\\d{1,2}-\\d{1,2} \\d{1,2}:\\d{1,2}', times):\n",
        "      result_year = time.strftime(\"%Y\", time.strptime(times, \"%Y-%m-%d %H:%M:%S\"))\n",
        "      result_month = time.strftime(\"%m\", time.strptime(times, \"%Y-%m-%d %H:%M:%S\"))   \n",
        "      result_day = time.strftime(\"%d\", time.strptime(times, \"%Y-%m-%d %H:%M:%S\")) #strptime作用是将第1个参数的格式与第2个参数匹配\n",
        "      result_hour = time.strftime(\"%H\", time.strptime(times, \"%Y-%m-%d %H:%M:%S\"))#strftime作用将第2个参数输出成第1个参数的形式\n",
        "    #names=li.find('p',class_='text').text\n",
        "    name=li.find('p',{\"class\": re.compile('[^\\d,\\.]+')}).string\n",
        "    names=re.findall('[^\\s,\\d,\\.:,\\-]+',name)#实现匹配除空格、数字、标点(.)的字符\n",
        "    link=li.find('img',class_='lazy_img')\n",
        "    if (link is not None): \n",
        "      links = link[\"data-original\"]\n",
        "      id=li.find('div',class_='point').get('id')\n",
        "      id=int(id)#id是属性值，所以要强转为int型\n",
        "      datas.clear()#清空datas中的数据\n",
        "      datas.append({\"n\":names,\"年\":result_year,\"月\":result_month,\"日\":result_day,\"时\":result_hour,\"id\":id}) \n",
        "    #下载照片\n",
        "      response = requests.get(links) #获取请求\n",
        "    #name = '233'  #图片名称\n",
        "      fb = open('/content/drive/My Drive/九嶷山/图片/%s.jpg'%str(id),'wb')  #wb代表以二进制方式写入\n",
        "      fb.write(response.content)  #写入\n",
        "      fb.close()  #关闭\n",
        "    #下载标签数据\n",
        "      with open(\"/content/drive/My Drive/九嶷山/json/%s.json\"%str(id), \"w\") as fout:\n",
        "        for data in datas:\n",
        "          fout.write(json.dumps(data, ensure_ascii=False)+\"\\n\")\n",
        "    else:\n",
        "      pass\n",
        "    #以src命名图片和json文件\n",
        "  return datas \n",
        "\n",
        "for idx in range(23,24):\n",
        "  result_list = []\n",
        "  time.sleep(1)\n",
        "  #九嶷山http://www.2bulu.com/track/list-%E4%B9%9D%E5%B6%B7%E5%B1%B1-----23.htm?sortType=2\n",
        "  url = f\"http://www.2bulu.com/track/list-%E4%B9%9D%E5%B6%B7%E5%B1%B1-----{idx+1}.htm?sortType=2\"\n",
        "  print(\"spider当前正在爬取第 %s 页的轨迹\"%(idx+1))\n",
        "  text = start_requests(url)\n",
        "  time.sleep(1)\n",
        "  pageurls = parse_music(text)#清理好的只有图片的二级链接集合\n",
        "  print(\"当前页面含有图片标记的轨迹数为 %s 条\"%len(pageurls))\n",
        "  flag=1\n",
        "  for pageurl in pageurls:\n",
        "    print(\"正在爬取第 %s 条链接 开始时间： %s\"%(flag,time.ctime()))\n",
        "    flag=flag+1\n",
        "    page = start_requests(pageurl)\n",
        "    jake = get_page_sourse(pageurl)\n",
        "\n",
        "    parse_page(jake)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "spider当前正在爬取第 24 页的轨迹\n",
            "http://www.2bulu.com/track/list-%E4%B9%9D%E5%B6%B7%E5%B1%B1-----24.htm?sortType=2\n",
            "当前页面含有图片标记的轨迹数为 2 条\n",
            "正在爬取第 1 条链接 开始时间： Wed Mar 25 07:48:58 2020\n",
            "http://www.2bulu.com/track/t-OXFeTaIk%252B9Lp%252FR2KBg5Tzw%253D%253D.htm?tabType=2\n",
            "正在爬取第 2 条链接 开始时间： Wed Mar 25 07:49:15 2020\n",
            "http://www.2bulu.com/track/t-mLrzUL4LzSY%253D.htm?tabType=2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqVEBJFOt8Bg",
        "colab_type": "code",
        "outputId": "494d2097-8a74-4a0d-da5b-0384ef4e0272",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import OrderedDict\n",
        "from threading import Thread\n",
        "from datetime import datetime\n",
        "start_time = datetime.now()\n",
        "\n",
        "def get_xici_proxy(url,headers):\n",
        "    response = requests.get(url, headers=headers).content\n",
        "    res = response.decode('utf-8')\n",
        "    soup = BeautifulSoup(res, 'lxml')\n",
        "    tag_tr_all = soup.find_all('tr')\n",
        "\n",
        "    info_names = tag_tr_all[0].get_text().strip().split('\\n')\n",
        "    # global proxy_list\n",
        "    t_list = []\n",
        "    for tag_tr in tag_tr_all[1:]:  \n",
        "        tag_td = tag_tr.find_all('td')#\n",
        "        try:\n",
        "            country = tag_td[0].img['alt'] \n",
        "        except TypeError:#\n",
        "            country = 'None'\n",
        "        try:\n",
        "            ip_info_list = [td.get_text(strip=True) for td in tag_td[1:]] \n",
        "            ip_info_list.insert(0,country)\n",
        "            ip_info_dict = OrderedDict(zip(info_names,ip_info_list))\n",
        "            t = Thread(target =check_proxy,args=(ip_info_dict,))\n",
        "            t_list.append(t)\n",
        "        except Exception as e:\n",
        "            print(\"登录错误\",e)\n",
        "    for i in range(len(tag_tr_all[1:])):\n",
        "        t_list[i].start()\n",
        "    for i in range(len(tag_tr_all[1:])):\n",
        "        t_list[i].join()\n",
        "\n",
        "def check_proxy(info):\n",
        "    proxy = {info['类型'].lower():r\"{}://{}:{}\".format(info['类型'].lower(),info['IP地址'],info['端口']),}\n",
        "    try:\n",
        "        response1 = requests.get(r\"http://httpbin.org/get\",proxies=proxy,timeout=10)\n",
        "        #print(response1.status_code)\n",
        "        if response1.status_code==200:\n",
        "            info['proxy'] = proxy\n",
        "            proxy_list.append(info)\n",
        "    except Exception as e:\n",
        "        pass#\n",
        "if __name__ == \"__main__\":\n",
        "    url = r\"https://www.xicidaili.com/nn\"\n",
        "    headers = {\n",
        "        'User-Agent': \"Mozilla/5.0 (Macintosh; U; Intel Mac OS X 10_6_8; en-us) AppleWebKit/534.50 (KHTML, like Gecko) Version/5.1 Safari/534.50\"\n",
        "    }\n",
        "    proxy_list = [] \n",
        "    get_xici_proxy(url,headers)\n",
        "\n",
        "    print(\"有效代理数：\",len(proxy_list))\n",
        "    print(\"第二个代理地址：\",proxy_list)\n",
        "    print(\"第二个代理地址类型：\",proxy_list[1].get('类型'))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "有效代理数： 44\n",
            "第二个代理地址： [OrderedDict([('国家', 'Cn'), ('IP地址', '222.95.240.228'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '22天'), ('验证时间', '20-03-21 14:20'), ('proxy', {'https': 'https://222.95.240.228:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '222.95.240.238'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '1分钟'), ('验证时间', '20-03-21 14:00'), ('proxy', {'https': 'https://222.95.240.238:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '222.95.241.123'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '1分钟'), ('验证时间', '20-03-21 13:00'), ('proxy', {'https': 'https://222.95.241.123:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '60.190.250.120'), ('端口', '8080'), ('服务器地址', '浙江杭州'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '624天'), ('验证时间', '20-03-21 11:21'), ('proxy', {'https': 'https://60.190.250.120:8080'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '222.95.144.72'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '20天'), ('验证时间', '20-03-21 11:20'), ('proxy', {'https': 'https://222.95.144.72:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '117.88.5.126'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '93天'), ('验证时间', '20-03-21 13:20'), ('proxy', {'https': 'https://117.88.5.126:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '117.88.176.25'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '1天'), ('验证时间', '20-03-21 11:00'), ('proxy', {'https': 'https://117.88.176.25:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '222.95.144.246'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '16天'), ('验证时间', '20-03-21 09:00'), ('proxy', {'https': 'https://222.95.144.246:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '222.95.241.104'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '1分钟'), ('验证时间', '20-03-21 13:00'), ('proxy', {'https': 'https://222.95.241.104:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '117.88.4.55'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '93天'), ('验证时间', '20-03-21 08:00'), ('proxy', {'https': 'https://117.88.4.55:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '117.88.4.215'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '1分钟'), ('验证时间', '20-03-21 07:00'), ('proxy', {'https': 'https://117.88.4.215:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '117.88.4.20'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '1分钟'), ('验证时间', '20-03-21 07:00'), ('proxy', {'https': 'https://117.88.4.20:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '61.150.96.27'), ('端口', '46111'), ('服务器地址', '陕西汉中'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '536天'), ('验证时间', '20-03-21 06:20'), ('proxy', {'https': 'https://61.150.96.27:46111'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '121.237.149.62'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '1分钟'), ('验证时间', '20-03-21 06:00'), ('proxy', {'https': 'https://121.237.149.62:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '119.254.94.71'), ('端口', '42788'), ('服务器地址', '北京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '501天'), ('验证时间', '20-03-21 05:20'), ('proxy', {'https': 'https://119.254.94.71:42788'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '117.88.5.207'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '1分钟'), ('验证时间', '20-03-21 05:00'), ('proxy', {'https': 'https://117.88.5.207:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '121.237.148.228'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '7天'), ('验证时间', '20-03-21 05:00'), ('proxy', {'https': 'https://121.237.148.228:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '171.221.79.246'), ('端口', '8118'), ('服务器地址', '四川'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '1天'), ('验证时间', '20-03-21 04:00'), ('proxy', {'https': 'https://171.221.79.246:8118'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '121.237.149.75'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '23天'), ('验证时间', '20-03-21 04:20'), ('proxy', {'https': 'https://121.237.149.75:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '117.88.177.3'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '81天'), ('验证时间', '20-03-21 03:20'), ('proxy', {'https': 'https://117.88.177.3:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '14.212.249.10'), ('端口', '8118'), ('服务器地址', '广东佛山'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '1分钟'), ('验证时间', '20-03-21 03:00'), ('proxy', {'https': 'https://14.212.249.10:8118'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '117.81.241.156'), ('端口', '8010'), ('服务器地址', '江苏苏州'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '574天'), ('验证时间', '20-03-21 02:21'), ('proxy', {'https': 'https://117.81.241.156:8010'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '117.88.176.158'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '22天'), ('验证时间', '20-03-21 02:00'), ('proxy', {'https': 'https://117.88.176.158:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '117.88.5.31'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '25天'), ('验证时间', '20-03-21 01:00'), ('proxy', {'https': 'https://117.88.5.31:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '218.21.96.128'), ('端口', '58080'), ('服务器地址', '广西玉林'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '18天'), ('验证时间', '20-03-21 01:20'), ('proxy', {'https': 'https://218.21.96.128:58080'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '117.88.4.13'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '1分钟'), ('验证时间', '20-03-21 01:00'), ('proxy', {'https': 'https://117.88.4.13:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '117.88.176.94'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '1分钟'), ('验证时间', '20-03-21 01:00'), ('proxy', {'https': 'https://117.88.176.94:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '222.95.144.122'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '19天'), ('验证时间', '20-03-20 23:20'), ('proxy', {'https': 'https://222.95.144.122:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '222.95.144.68'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '2天'), ('验证时间', '20-03-20 23:20'), ('proxy', {'https': 'https://222.95.144.68:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '110.73.42.30'), ('端口', '8123'), ('服务器地址', '广西南宁'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '900天'), ('验证时间', '20-03-20 23:20'), ('proxy', {'https': 'https://110.73.42.30:8123'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '222.95.144.171'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '1分钟'), ('验证时间', '20-03-20 23:00'), ('proxy', {'https': 'https://222.95.144.171:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '117.88.176.252'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '6天'), ('验证时间', '20-03-20 22:20'), ('proxy', {'https': 'https://117.88.176.252:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '117.88.177.207'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '5天'), ('验证时间', '20-03-20 22:00'), ('proxy', {'https': 'https://117.88.177.207:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '121.237.149.237'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '1分钟'), ('验证时间', '20-03-20 22:00'), ('proxy', {'https': 'https://121.237.149.237:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '222.95.144.211'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '1分钟'), ('验证时间', '20-03-20 22:00'), ('proxy', {'https': 'https://222.95.144.211:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '222.95.240.51'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '20天'), ('验证时间', '20-03-20 22:00'), ('proxy', {'https': 'https://222.95.240.51:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '58.56.149.198'), ('端口', '53281'), ('服务器地址', '山东青岛'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '916天'), ('验证时间', '20-03-20 20:00'), ('proxy', {'https': 'https://58.56.149.198:53281'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '221.218.102.146'), ('端口', '33323'), ('服务器地址', '北京'), ('是否匿名', '高匿'), ('类型', 'HTTPS'), ('速度', ''), ('连接时间', ''), ('存活时间', '541天'), ('验证时间', '20-03-20 19:00'), ('proxy', {'https': 'https://221.218.102.146:33323'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '117.62.173.31'), ('端口', '8118'), ('服务器地址', '江苏'), ('是否匿名', '高匿'), ('类型', 'HTTP'), ('速度', ''), ('连接时间', ''), ('存活时间', '3天'), ('验证时间', '20-03-21 12:20'), ('proxy', {'http': 'http://117.62.173.31:8118'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '117.87.180.144'), ('端口', '8118'), ('服务器地址', '江苏徐州'), ('是否匿名', '高匿'), ('类型', 'HTTP'), ('速度', ''), ('连接时间', ''), ('存活时间', '19天'), ('验证时间', '20-03-21 09:00'), ('proxy', {'http': 'http://117.87.180.144:8118'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '117.88.177.95'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTP'), ('速度', ''), ('连接时间', ''), ('存活时间', '1分钟'), ('验证时间', '20-03-21 14:20'), ('proxy', {'http': 'http://117.88.177.95:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '117.88.177.120'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTP'), ('速度', ''), ('连接时间', ''), ('存活时间', '106天'), ('验证时间', '20-03-21 01:20'), ('proxy', {'http': 'http://117.88.177.120:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '121.237.148.232'), ('端口', '3000'), ('服务器地址', '江苏南京'), ('是否匿名', '高匿'), ('类型', 'HTTP'), ('速度', ''), ('连接时间', ''), ('存活时间', '14天'), ('验证时间', '20-03-21 14:20'), ('proxy', {'http': 'http://121.237.148.232:3000'})]), OrderedDict([('国家', 'Cn'), ('IP地址', '106.122.205.36'), ('端口', '8118'), ('服务器地址', '广东'), ('是否匿名', '高匿'), ('类型', 'HTTP'), ('速度', ''), ('连接时间', ''), ('存活时间', '20天'), ('验证时间', '20-03-21 09:20'), ('proxy', {'http': 'http://106.122.205.36:8118'})])]\n",
            "第二个代理地址类型： HTTPS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tT9uOjnxbdA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv /content/xml/* /content/drive/My\\ Drive/xml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTBrX8xyvMx0",
        "colab_type": "code",
        "outputId": "609839a4-1757-4a0e-8e5a-cadfe4efc12e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from selenium import webdriver\n",
        "\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument('--headless')\n",
        "options.add_argument('--proxy-server=http://222.95.240.228:3000')\n",
        "options.add_argument('--no-sandbox')\n",
        "options.add_argument('--disable-dev-shm-usage')\n",
        "options.add_argument('User-Agent:\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36\"')\n",
        "driver = webdriver.Chrome('chromedriver', options=options)\n",
        "driver.get(\"http://httpbin.org/ip\")\n",
        "page_sourse=driver.page_source\n",
        "print(page_sourse)\n",
        "driver.close()\n",
        "\n",
        "\n",
        "\n",
        "# 查看本机ip，查看代理是否起作用\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<html><head></head><body></body></html>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vOWBlCAfg7K",
        "colab_type": "code",
        "outputId": "6e18e82a-f487-4d41-ecc3-78c52b675916",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "path =\"/content/drive/My Drive/图片\"\n",
        "count = 0\n",
        "for fn in os.listdir(path): #fn 表示的是文件名#原来共12923个图片\n",
        "        count = count+1\n",
        "print(count)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLZTLcL_agXa",
        "colab_type": "code",
        "outputId": "fa28d2e8-3919-494d-e6b0-e4400623bde6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        }
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import hashlib\n",
        "from time import clock as now\n",
        "\n",
        "def get_token(filename):\n",
        "    #pic = new.strip() # or new.split()[index]\n",
        "    #hs = hashlib.md5(new.encode()).hexdigest()\n",
        "    #print(pic)\n",
        "    #m1 = hashlib.md5()\n",
        "    #m1.update(pic)\n",
        "    #token = m1.hexdigest()\n",
        "    #print(token)\n",
        "  with open(filename, mode='rb') as f:\n",
        "    d = hashlib.md5()\n",
        "    while True:\n",
        "      buf = f.read(4096) # 128 is smaller than the typical filesystem block\n",
        "      if not buf:\n",
        "        break\n",
        "      d.update(buf) \n",
        "    return d.hexdigest()\n",
        "    \n",
        "\n",
        "\n",
        "def find_the_same_pic(cwd, xml):\n",
        "    for path, d, filelist in os.walk(cwd):\n",
        "        print(path)\n",
        "        filelist = sorted(filelist)\n",
        "        #filelist = filelist[600:]\n",
        "        for imgname in filelist:\n",
        "            print(imgname)\n",
        "            if imgname.endswith('jpg'):\n",
        "                oldname1 = os.path.join(path, imgname)\n",
        "                print('the old pic : ', oldname1)\n",
        "                filelist.remove(imgname)\n",
        "                #img1 = cv2.imread(oldname1)\n",
        "                #print(img1)\n",
        "                #img1 = cv2.resize(img1, (540, 960))\n",
        "                img1md5 = get_token(oldname1)\n",
        "                for imgname1 in filelist:\n",
        "                    if imgname1.endswith('jpg'):\n",
        "                        oldname2 = os.path.join(path, imgname1)\n",
        "                        # print(oldname2)\n",
        "                        #img2 = cv2.imread(oldname2)\n",
        "                        #print(oldname2)\n",
        "                        #img2 = cv2.resize(img2, (540, 960))\n",
        "                        img2md5 = get_token(oldname2)\n",
        "                        # img = img2 - img1\n",
        "                        # a = max(sum(sum(img)))\n",
        "                        result = (img1md5 == img2md5)\n",
        "                        #result = not np.any(difference)\n",
        "\n",
        "                        if result is True :\n",
        "                            print('the_same : ', oldname1, oldname2)\n",
        "                            rm_same_pic_and_xml(cwd, imgname1, xml)\n",
        "                            filelist.remove(imgname1)\n",
        "\n",
        "                        else:\n",
        "                            pass\n",
        "def rm_same_pic_and_xml(cwd, imgname, xml):\n",
        "    xmlname = imgname.split('.')[0] + '.xml'\n",
        "\n",
        "    pic_file = os.path.join(cwd, imgname)\n",
        "    xml_file = os.path.join(xml, xmlname)\n",
        "    os.remove(pic_file)\n",
        "    os.remove(xml_file)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    cwd = r'/content/drive/My Drive/图片'\n",
        "\n",
        "    xml = r'/content/drive/My Drive/xml'\n",
        "\n",
        "\n",
        "    find_the_same_pic(cwd, xml)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/图片\n",
            "100313391.jpg\n",
            "the old pic :  /content/drive/My Drive/图片/100313391.jpg\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-37d94548e1d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mfind_the_same_pic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-37d94548e1d7>\u001b[0m in \u001b[0;36mfind_the_same_pic\u001b[0;34m(cwd, xml)\u001b[0m\n\u001b[1;32m     47\u001b[0m                         \u001b[0;31m#print(oldname2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                         \u001b[0;31m#img2 = cv2.resize(img2, (540, 960))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                         \u001b[0mimg2md5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moldname2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                         \u001b[0;31m# img = img2 - img1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                         \u001b[0;31m# a = max(sum(sum(img)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-37d94548e1d7>\u001b[0m in \u001b[0;36mget_token\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhashlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmd5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m       \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 128 is smaller than the typical filesystem block\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS_8zq99b6Yu",
        "colab_type": "code",
        "outputId": "db1bb7a8-2e15-48b0-c15e-2846be0234f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# -*- coding: cp936 -*-\n",
        "import hashlib\n",
        "import os\n",
        "import time\n",
        "\n",
        "\n",
        "def getmd5(filename):\n",
        "    \"\"\"\n",
        "    获取文件 md5 码\n",
        "    :param filename: 文件路径\n",
        "    :return: 文件 md5 码\n",
        "    \"\"\"\n",
        "    file_txt = open(filename, 'rb').read()\n",
        "    # 调用一个md5对象\n",
        "    m = hashlib.md5(file_txt)\n",
        "    # hexdigest()方法来获取摘要（加密结果）\n",
        "    return m.hexdigest()\n",
        "\n",
        "\n",
        "def main():\n",
        "    # 文件夹路径\n",
        "    path = input(\"path: \")\n",
        "    # 键为文件大小, 值为列表（文件路径、md5）\n",
        "    all_size = {}\n",
        "    total_file = 0\n",
        "    total_delete = 0\n",
        "    # 开始时间\n",
        "    start = time.time()\n",
        "    # 遍历文件夹下的所有文件\n",
        "    for file in os.listdir(path):\n",
        "        # 文件数量加 1\n",
        "        total_file += 1\n",
        "        # 文件的路径\n",
        "        real_path = os.path.join(path, file)\n",
        "        # 判断文件是否是文件\n",
        "        if os.path.isfile(real_path) == True:\n",
        "            # 获取文件大小\n",
        "            size = os.stat(real_path).st_size\n",
        "            # md5(默认为空)\n",
        "            size_and_md5 = [\"\"]\n",
        "            # 如果文件大小已存在\n",
        "            if size in all_size.keys():\n",
        "                # 获取文件的md5码\n",
        "                new_md5 = getmd5(real_path)\n",
        "                # 大小相同，md5 为空，添加md5\n",
        "                if all_size[size][0] == \"\":\n",
        "                    all_size[size][0] = new_md5\n",
        "                # md5 已存在，删除\n",
        "                if new_md5 in all_size[size]:\n",
        "                    print('删除的图片路径： ', real_path)\n",
        "                    pure_path=os.path.splitext(os.path.basename(real_path))[0]\n",
        "                    pure= '/content/drive/My Drive/xml/%s'%pure_path + '.xml'\n",
        "                    os.remove(pure)\n",
        "                    #print(\"删除的xml路径为： \"，pure)\n",
        "                    os.remove(real_path)\n",
        "                    total_delete += 1\n",
        "                else:\n",
        "                    # md5 不存在，进行添加\n",
        "                    all_size[size].append(new_md5)\n",
        "            else:\n",
        "                # 如果文件大小不存在，则将此文件大小添加到 all_size 字典中\n",
        "                all_size[size] = size_and_md5\n",
        "    # 结束时间\n",
        "    end = time.time()\n",
        "    time_last = end - start\n",
        "    print('文件总数：', total_file)\n",
        "    print('删除个数：', total_delete)\n",
        "    print('耗时：', time_last, '秒')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "path: /content/drive/My Drive/图片\n",
            "删除的图片路径：  /content/drive/My Drive/图片/147511071.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/105410886.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/157213296.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/107672620.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/180938185.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/180328149.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/7671984.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/79814236.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/163277423.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/73685788.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/73685798.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/129814622.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/72492377.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/71719055.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/71719118.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/59591489.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/100493536.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/100493547.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/100493587.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/100493628.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/93355871.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/93355907.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/93355937.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/93355977.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/87568190.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/136422501.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/110767880.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/110767894.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/110767905.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/110767945.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/109276179.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/196574183.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/105887260.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/122010651.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/181415290.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/105223799.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/102937397.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/104857871.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/104857915.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/123907317.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/110757973.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/110757975.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/110757992.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/110758013.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/110758064.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/110758086.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/109829763.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/109829788.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/110165903.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/229983164.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/109323375.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/200290716.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/200290761.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/110767861.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/126625413.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/126128175.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/126128189.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/126128195.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/126128196.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/126728753.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/126728775.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/124947512.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/124176887.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/117765082.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/117765162.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/119744409.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/119744425.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/119525032.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/119525083.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/110757940.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/110757946.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/142997176.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/142839627.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/142839637.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/148246427.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/148246428.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/148246449.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/142428261.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/142428263.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/130573543.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/130573557.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/130573561.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/130573677.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/130573737.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/130573764.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/162298870.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/162298879.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/126556504.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/150096098.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/150582029.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/150582041.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/150582043.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/150582066.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/150582092.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/150582106.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/146137241.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/158370348.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/158370364.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/213254809.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/177768231.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/177768252.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/177768286.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/177768287.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/177768304.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/145473349.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/145473350.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/143349435.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/143349444.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/143349468.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/143349475.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/143349500.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/150752086.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/142997153.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/142997154.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/162267150.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/162267156.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/157918206.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/157918248.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/157918255.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/157918256.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/157918261.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/157918270.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/184670311.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/184670314.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/184670315.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/184670319.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/184670346.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/184670352.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/184670361.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/184670365.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/170785325.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/158169019.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/158169036.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/158169050.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/158169134.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/158169296.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/158169291.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/158169306.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/223576357.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/150262272.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/170993960.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/170993973.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/178221670.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174724971.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174724970.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174724963.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174724958.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174724949.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174724943.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174724980.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174724982.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174724996.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174724999.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174725000.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174725006.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174724928.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174725009.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/166772146.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/166772156.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/181059090.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/167683915.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/158274386.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/158274397.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/158274407.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/158274436.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/158169606.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/162267136.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/180503204.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/180503142.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/180503179.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/180503181.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/180503182.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/180503201.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/180503189.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/180503196.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/175856472.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/175856475.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/176140192.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/175818205.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/175850193.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/175849981.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174991956.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174991958.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174991965.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174991984.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174652407.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174652411.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174652424.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/174652427.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/170993945.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/195535474.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/204734983.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/196146366.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/189491383.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/189491389.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/187281919.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/186623266.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/186623269.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/181308708.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/181308758.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/181057209.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/181057210.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/180839944.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/181343245.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/181343274.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/180660099.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/181358360.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/181358399.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/181358425.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/180718002.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/225449127.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/225449130.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/225449157.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/197367196.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/197367197.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/197367198.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/210730147.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/202224740.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/195326565.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/195326567.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/195839254.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/195839258.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/195839266.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/195839224.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/210029173.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/191597276.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/195360231.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/195535464.jpg\n",
            "删除的图片路径：  /content/drive/My Drive/图片/195535470.jpg\n",
            "文件总数： 6218\n",
            "删除个数： 229\n",
            "耗时： 64.20843601226807 秒\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ae-hf6S-kfch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp /content/图片/1.jpg /content/xml/1.xml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3TbKHrUlStu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv *.jpg /content/图片"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75oTNkV44xTx",
        "colab_type": "code",
        "outputId": "83fd9af9-7f07-4d93-91af-4cb96a3242c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import re \n",
        "import os\n",
        "xml = '/content/图片/1.jpg'\n",
        "pure_path=os.path.splitext(os.path.basename(xml))[0]\n",
        "pure= '/content/xml/%s'%pure_path + '.xml'\n",
        "os.remove(pure)\n",
        "print(\"删除的图片为： \"pure)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/xml/1.xml\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}